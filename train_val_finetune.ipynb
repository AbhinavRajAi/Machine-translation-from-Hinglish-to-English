{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dqmMmcQF9CI7","executionInfo":{"status":"ok","timestamp":1701876884073,"user_tz":-330,"elapsed":23088,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"fd339d19-0f29-415b-d0f2-7be5e3faa8bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece\n","!pip install sacremoses\n","!pip install git+https://github.com/nltk/nltk_contrib.git#egg=nltk_contrib\n","!pip install jiwer nltk sacrebleu rouge-score\n","!pip install --upgrade jiwer\n","!pip install torchmetrics\n","!pip install evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Y59Ayngjxsr","executionInfo":{"status":"ok","timestamp":1701876953442,"user_tz":-330,"elapsed":65954,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"26d161dd-bdc9-4210-985c-9b84ae859eec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Collecting sacremoses\n","  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.6.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.1)\n","Installing collected packages: sacremoses\n","Successfully installed sacremoses-0.1.1\n","Collecting nltk_contrib\n","  Cloning https://github.com/nltk/nltk_contrib.git to /tmp/pip-install-3zs0bj7e/nltk-contrib_9b32091f6ed54b81b25034b1d12c31b3\n","  Running command git clone --filter=blob:none --quiet https://github.com/nltk/nltk_contrib.git /tmp/pip-install-3zs0bj7e/nltk-contrib_9b32091f6ed54b81b25034b1d12c31b3\n","  Resolved https://github.com/nltk/nltk_contrib.git to commit 95d1806e2f4e89e960b76a685b1fba2eaa7d5142\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: nltk_contrib\n","  Building wheel for nltk_contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk_contrib: filename=nltk_contrib-3.8.1-py3-none-any.whl size=682136 sha256=9dbcce04813cc023a9d4c19d6809b3f91cdd363c6e4ed3d0d2c4f8d25f7066db\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-c31gkmul/wheels/df/ab/e3/f99b22cdc83586c32ba851d962379a56a1e7f1bdb50aa41f7a\n","Successfully built nltk_contrib\n","Installing collected packages: nltk_contrib\n","Successfully installed nltk_contrib-3.8.1\n","Collecting jiwer\n","  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n","Collecting rapidfuzz<4,>=3 (from jiwer)\n","  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n","Collecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=6fa4838c54a8132ce29cdd69d3978bb204050ce65c509f54405f6b3fbf30063b\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: rapidfuzz, portalocker, colorama, sacrebleu, rouge-score, jiwer\n","Successfully installed colorama-0.4.6 jiwer-3.0.3 portalocker-2.8.2 rapidfuzz-3.5.2 rouge-score-0.1.2 sacrebleu-2.3.3\n","Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n","Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.5.2)\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n","Collecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n","  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n","Collecting dill (from evaluate)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Collecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Installing collected packages: pyarrow-hotfix, dill, responses, multiprocess, datasets, evaluate\n","Successfully installed datasets-2.15.0 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0\n"]}]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import MarianMTModel, MarianTokenizer, AdamW,AutoTokenizer\n","from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n","import sacrebleu\n","from nltk.translate.meteor_score import meteor_score\n","import jiwer\n","from jiwer import wer\n","from rouge_score import rouge_scorer\n","from torchmetrics.text import TranslationEditRate\n","from tqdm import tqdm\n","from transformers import AutoModelForSeq2SeqLM\n","from transformers import T5ForConditionalGeneration, T5Tokenizer"],"metadata":{"id":"lQvtSKhg03ca"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["train"],"metadata":{"id":"9aG_0adMe5a2"}},{"cell_type":"code","source":["train_df = pd.read_csv(\"/content/drive/MyDrive/nlp_project/Dataset/train.tsv\",delimiter='\\t')\n","val_df = pd.read_csv(\"/content/drive/MyDrive/nlp_project/Dataset/val.tsv\",delimiter='\\t')"],"metadata":{"id":"NECLkxpVarSM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TranslationDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-cs\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(' '.join(input_text.split()[:100]), return_tensors='pt', truncation=True,max_length=100,padding='max_length')['input_ids'].squeeze()\n","        labels = self.tokenizer(' '.join(target_text.split()[:100]), return_tensors='pt', truncation=True,max_length=100,padding='max_length')['input_ids'].squeeze()\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels}"],"metadata":{"id":"g0DQu9hqViFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the translation dataset with references\n","class TranslationDatasetWithRefs(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-cs\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(' '.join(input_text.split()[:100]), return_tensors='pt',truncation=True,padding='max_length', max_length=100)['input_ids'].squeeze()\n","        labels = self.tokenizer(' '.join(target_text.split()[:100]), return_tensors='pt',truncation=True,padding='max_length', max_length=100)['input_ids'].squeeze()\n","\n","        # Convert labels to text without special tokens\n","        references = [self.tokenizer.decode(labels, skip_special_tokens=True)]\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels, \"references\": references}"],"metadata":{"id":"5EAll7odnVYv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create translation datasets and dataloaders for training and validation\n","train_dataset = TranslationDataset(train_df[:100000])\n","train_dataloader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n","val_dataset = TranslationDatasetWithRefs(val_df)\n","val_dataloader = DataLoader(val_dataset, batch_size=50, shuffle=False)  # No need to shuffle validation data"],"metadata":{"id":"pR4itRciBT9W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### MarianMT"],"metadata":{"id":"u5hwvRSvAeOU"}},{"cell_type":"code","source":["# Set up the model and optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-cs\").to(device)\n","optimizer = AdamW(model.parameters(), lr=5e-5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HLYBqvNG-6hm","executionInfo":{"status":"ok","timestamp":1701872134032,"user_tz":-330,"elapsed":5001,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"4cfa0f86-6db0-4c5a-f1c3-fd961aa0b2c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Fine-tuning loop with validation and model checkpointing\n","num_epochs = 3\n","best_bleu = 0.0\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    model.train()\n","\n","    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\"):\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    average_loss = total_loss / len(train_dataloader)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}: Training Loss - {average_loss}\")\n","\n","    # Validation loop\n","    model.eval()\n","    bleu_scores = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(val_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Validation)\"):\n","            input_ids = batch['input_ids'].to(device)\n","            labels = batch['labels'].to(device)\n","            references = batch['references']\n","\n","            # Generate predictions\n","            generated_ids = model.generate(input_ids, max_length=128)  # Adjust max_length as needed\n","\n","            # Convert generated IDs to text\n","            predictions = [val_dataset.tokenizer.decode(generated_ids[0], skip_special_tokens=True)]\n","\n","            # Calculate BLEU score\n","            bleu_score = corpus_bleu(references, predictions)\n","            bleu_scores.append(bleu_score)\n","\n","    # Calculate average BLEU score\n","    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}: Average BLEU - {avg_bleu}\\n\")\n","\n","    # Save the model if the average BLEU score is the best so far\n","    if avg_bleu > best_bleu:\n","        best_bleu = avg_bleu\n","        model.save_pretrained(\"/content/drive/MyDrive/nlp_project/results/MarianMT/best_model\")\n","        print(\"best model saved!\\n\\n\")\n","\n","print(\"Training completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ic45sdMXh5eW","executionInfo":{"status":"ok","timestamp":1701875827574,"user_tz":-330,"elapsed":2635526,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"449419b7-c4df-44d2-90dc-c593d75815df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/3 (Training): 100%|██████████| 2000/2000 [08:47<00:00,  3.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3: Training Loss - 0.09966550359874964\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/3 (Validation):  90%|█████████ | 431/477 [05:42<00:32,  1.41it/s]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","Epoch 1/3 (Validation): 100%|██████████| 477/477 [06:20<00:00,  1.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3: Average BLEU - 0.9522358392499927\n","\n","best model saved!\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3 (Training): 100%|██████████| 2000/2000 [08:45<00:00,  3.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3: Training Loss - 0.07117461261712014\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3 (Validation): 100%|██████████| 477/477 [05:41<00:00,  1.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3: Average BLEU - 0.9630123585905087\n","\n","best model saved!\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3 (Training): 100%|██████████| 2000/2000 [08:40<00:00,  3.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3: Training Loss - 0.05967495138756931\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3 (Validation): 100%|██████████| 477/477 [05:38<00:00,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3: Average BLEU - 0.9629942724934702\n","\n","Training completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"e5Kre-TH_pjf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AZo6fGom_pgF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mj0OHWMS_pd6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### MBART\n"],"metadata":{"id":"2E1UW74OsMnh"}},{"cell_type":"code","source":["class TranslationDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(input_text, return_tensors='pt', truncation=True,\n","                                    max_length=50, padding='max_length')['input_ids'].squeeze()\n","        labels = self.tokenizer(target_text, return_tensors='pt', truncation=True,\n","                                 max_length=50, padding='max_length')['input_ids'].squeeze()\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels}"],"metadata":{"id":"WxiHgUOrsxlp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the translation dataset with references\n","class TranslationDatasetWithRefs(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(' '.join(input_text.split()[:50]), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","        labels = self.tokenizer(' '.join(target_text.split()[:50]), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","\n","        # Convert labels to text without special tokens\n","        references = [self.tokenizer.decode(labels, skip_special_tokens=True)]\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels, \"references\": references}"],"metadata":{"id":"EmGMvZrZszFN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create translation datasets and dataloaders for training and validation\n","train_dataset = TranslationDataset(train_df[:50000])\n","train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","val_dataset = TranslationDatasetWithRefs(val_df)\n","val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)  # No need to shuffle validation data"],"metadata":{"id":"w_t9TNIHs4LA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up the model and optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Choose your MBART model\n","model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n","# Load the MBART model\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n","optimizer = AdamW(model.parameters(), lr=5e-5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"glezaB0Ms7pv","executionInfo":{"status":"ok","timestamp":1701877204847,"user_tz":-330,"elapsed":21716,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"cacab9c1-8607-4d8c-bdf2-a602b8e05451"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Fine-tuning loop with validation and model checkpointing\n","num_epochs = 3\n","best_bleu = 0.0\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    model.train()\n","\n","    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\"):\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    average_loss = total_loss / len(train_dataloader)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}: Training Loss - {average_loss}\")\n","\n","    # Validation loop\n","    model.eval()\n","    bleu_scores = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(val_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Validation)\"):\n","            input_ids = batch['input_ids'].to(device)\n","            labels = batch['labels'].to(device)\n","            references = batch['references']\n","\n","            # Generate predictions\n","            generated_ids = model.generate(input_ids, max_length=128)  # Adjust max_length as needed\n","\n","            # Convert generated IDs to text\n","            predictions = [val_dataset.tokenizer.decode(generated_ids[0], skip_special_tokens=True)]\n","\n","            # Calculate BLEU score\n","            bleu_score = corpus_bleu(references, predictions)\n","            bleu_scores.append(bleu_score)\n","\n","    # Calculate average BLEU score\n","    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}: Average BLEU - {avg_bleu}\\n\")\n","\n","    # Save the model if the average BLEU score is the best so far\n","    if avg_bleu > best_bleu:\n","        best_bleu = avg_bleu\n","        model.save_pretrained(\"/content/drive/MyDrive/nlp_project/results/MBART_large/best_model\")\n","        print(\"best model saved!\\n\\n\")\n","\n","print(\"Training completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mQGtw4K8sN0w","executionInfo":{"status":"ok","timestamp":1701885511539,"user_tz":-330,"elapsed":8306707,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"6ce33be1-e962-4b0a-cc20-3ee4da991f18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/3 (Training): 100%|██████████| 6250/6250 [22:54<00:00,  4.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3: Training Loss - 0.15761706722021102\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/3 (Validation):  56%|█████▌    | 1657/2977 [12:49<11:24,  1.93it/s]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","Epoch 1/3 (Validation): 100%|██████████| 2977/2977 [23:02<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3: Average BLEU - 0.9150602215896705\n","\n","best model saved!\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3 (Training): 100%|██████████| 6250/6250 [22:55<00:00,  4.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3: Training Loss - 0.08827320582807065\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3 (Validation):  56%|█████▌    | 1657/2977 [12:49<11:25,  1.93it/s]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","Epoch 2/3 (Validation): 100%|██████████| 2977/2977 [22:57<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3: Average BLEU - 0.9189482670400909\n","\n","best model saved!\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3 (Training): 100%|██████████| 6250/6250 [22:57<00:00,  4.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3: Training Loss - 0.06902846349552273\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3 (Validation):  56%|█████▌    | 1657/2977 [12:52<11:22,  1.93it/s]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","Epoch 3/3 (Validation): 100%|██████████| 2977/2977 [23:11<00:00,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3: Average BLEU - 0.9226437472187894\n","\n","best model saved!\n","\n","\n","Training completed.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Ri54D5p7sNyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JBhkptzVmT9o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nRLUHub0mT6U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### MT5"],"metadata":{"id":"dzZHLVVoV-EX"}},{"cell_type":"code","source":["# Set up the model and optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","# Load the T5 model\n","model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n","optimizer = AdamW(model.parameters(), lr=5e-5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwtUtVooWADS","executionInfo":{"status":"ok","timestamp":1701887015875,"user_tz":-330,"elapsed":3604,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"6805151e-ab1b-4368-b4b1-0397bef3bcd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["class TranslationDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(input_text, return_tensors='pt', truncation=True,\n","                                    max_length=50, padding='max_length')['input_ids'].squeeze()\n","        labels = self.tokenizer(target_text, return_tensors='pt', truncation=True,\n","                                 max_length=50, padding='max_length')['input_ids'].squeeze()\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels}"],"metadata":{"id":"sYSW1N8tV_9S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the translation dataset with references\n","class TranslationDatasetWithRefs(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(' '.join(input_text.split()[:50]), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","        labels = self.tokenizer(' '.join(target_text.split()[:50]), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","\n","        # Convert labels to text without special tokens\n","        references = [self.tokenizer.decode(labels, skip_special_tokens=True)]\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels, \"references\": references}"],"metadata":{"id":"BgGaFK_QWjzG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create translation datasets and dataloaders for training and validation\n","train_dataset = TranslationDataset(train_df[:50000])\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_dataset = TranslationDatasetWithRefs(val_df)\n","val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)  # No need to shuffle validation data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fi43lqAjWsS5","executionInfo":{"status":"ok","timestamp":1701887156134,"user_tz":-330,"elapsed":1047,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"a402efa2-a904-464f-f411-8c0d36998157"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["# Fine-tuning loop with validation and model checkpointing\n","num_epochs = 3\n","best_bleu = 0.0\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    model.train()\n","\n","    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\"):\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    average_loss = total_loss / len(train_dataloader)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}: Training Loss - {average_loss}\")\n","\n","    # Validation loop\n","    model.eval()\n","    bleu_scores = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(val_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Validation)\"):\n","            input_ids = batch['input_ids'].to(device)\n","            labels = batch['labels'].to(device)\n","            references = batch['references']\n","\n","            # Generate predictions\n","            generated_ids = model.generate(input_ids, max_length=50)  # Adjust max_length as needed\n","\n","            # Convert generated IDs to text\n","            predictions = [val_dataset.tokenizer.decode(generated_ids[0], skip_special_tokens=True)]\n","\n","            # Calculate BLEU score\n","            bleu_score = corpus_bleu(references, predictions)\n","            bleu_scores.append(bleu_score)\n","\n","    # Calculate average BLEU score\n","    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}: Average BLEU - {avg_bleu}\\n\")\n","\n","    # Save the model if the average BLEU score is the best so far\n","    if avg_bleu > best_bleu:\n","        best_bleu = avg_bleu\n","        model.save_pretrained(\"/content/drive/MyDrive/nlp_project/results/MT5_small/best_model\")\n","        print(\"best model saved!\\n\\n\")\n","\n","print(\"Training completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uuOv5_SuWt_i","executionInfo":{"status":"ok","timestamp":1701888719401,"user_tz":-330,"elapsed":1561985,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"7c5654b8-55b9-4dfc-b365-d0b37276c3bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/3 (Training): 100%|██████████| 1563/1563 [02:02<00:00, 12.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3: Training Loss - 0.5528093915068027\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/3 (Validation):  37%|███▋      | 275/745 [02:49<04:50,  1.62it/s]/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","Epoch 1/3 (Validation): 100%|██████████| 745/745 [07:39<00:00,  1.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3: Average BLEU - 0.7256025620721318\n","\n","best model saved!\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3 (Training): 100%|██████████| 1563/1563 [02:03<00:00, 12.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3: Training Loss - 0.3247207480215218\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3 (Validation): 100%|██████████| 745/745 [06:20<00:00,  1.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3: Average BLEU - 0.7771388735043575\n","\n","best model saved!\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3 (Training): 100%|██████████| 1563/1563 [02:03<00:00, 12.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3: Training Loss - 0.26968117788557966\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3 (Validation): 100%|██████████| 745/745 [05:49<00:00,  2.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3: Average BLEU - 0.8018909409174928\n","\n","best model saved!\n","\n","\n","Training completed.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rpRpigDeWt8L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6nrBDpBmWt5W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tqaZnLJsWt2p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Fine tune MBART on phinc dataset"],"metadata":{"id":"7Ei29D24dBdM"}},{"cell_type":"code","source":["train_df = pd.read_csv(\"/content/drive/MyDrive/nlp_project/Dataset/phinc/train.csv\")"],"metadata":{"id":"MVxOaP00gbc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TranslationDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(' '.join(str(input_text).split()[:50]), return_tensors='pt', truncation=True,max_length=50,padding='max_length')['input_ids'].squeeze()\n","        labels = self.tokenizer(' '.join(str(target_text).split()[:50]), return_tensors='pt', truncation=True,max_length=50,padding='max_length')['input_ids'].squeeze()\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels}"],"metadata":{"id":"Oom2DVNAdJKk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create translation datasets and dataloaders for training and validation\n","train_dataset = TranslationDataset(train_df)\n","train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)"],"metadata":{"id":"NoQKSVqWgHn_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up the model and optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/nlp_project/results/MBART_large/best_model\").to(device)\n","optimizer = AdamW(model.parameters(), lr=5e-5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BD9TaD0PeD95","executionInfo":{"status":"ok","timestamp":1701889515256,"user_tz":-330,"elapsed":21556,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"b97d9e42-5f41-4dd9-d313-4a8b7f68f1e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Fine-tuning loop with validation and model checkpointing\n","num_epochs = 3\n","best_loss = 9999\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    model.train()\n","\n","    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\"):\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    average_loss = total_loss / len(train_dataloader)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}: Training Loss - {average_loss}\")\n","\n","    if average_loss > best_loss:\n","        best_loss = average_loss\n","        model.save_pretrained(\"/content/drive/MyDrive/nlp_project/results/MBART_finetune/best_model_fine\")\n","        print(\"best model saved!\\n\\n\")\n","\n","print(\"Training completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50BQDwsadJHO","executionInfo":{"status":"ok","timestamp":1701890601981,"user_tz":-330,"elapsed":797735,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"0dd7b4e3-973f-4623-dc53-f4e0c1fd2e0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/3 (Training): 100%|██████████| 1202/1202 [04:25<00:00,  4.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3: Training Loss - 0.48302928760598185\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3 (Training): 100%|██████████| 1202/1202 [04:25<00:00,  4.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3: Training Loss - 0.277462662121718\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3 (Training): 100%|██████████| 1202/1202 [04:25<00:00,  4.52it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3: Training Loss - 0.13785264624620536\n","Training completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["model.save_pretrained(\"/content/drive/MyDrive/nlp_project/results/MBART_finetune/best_model_fine\")"],"metadata":{"id":"cF6pAeU7dJEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EjtmbKn4l1S7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6F_ptUnil1Pj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7QvPU94Ll1M9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Fine tune MT5 on phinc"],"metadata":{"id":"hpXry1cfioUY"}},{"cell_type":"code","source":["train_df = pd.read_csv(\"/content/drive/MyDrive/nlp_project/Dataset/phinc/train.csv\")"],"metadata":{"id":"ITllThs8dJBR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TranslationDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(' '.join(str(input_text).split()[:50]), return_tensors='pt', truncation=True,max_length=50,padding='max_length')['input_ids'].squeeze()\n","        labels = self.tokenizer(' '.join(str(target_text).split()[:50]), return_tensors='pt', truncation=True,max_length=50,padding='max_length')['input_ids'].squeeze()\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels}"],"metadata":{"id":"TO8duPJ1dI-c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create translation datasets and dataloaders for training and validation\n","train_dataset = TranslationDataset(train_df)\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzbPqQiedI7v","executionInfo":{"status":"ok","timestamp":1701890856995,"user_tz":-330,"elapsed":1630,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"b93c7715-656e-496a-9178-2851e30cade4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["# Set up the model and optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","# Load the T5 model\n","model = T5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/nlp_project/results/MT5_small/best_model\").to(device)\n","optimizer = AdamW(model.parameters(), lr=5e-5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7hZ-2yGmbZ7","executionInfo":{"status":"ok","timestamp":1701890913798,"user_tz":-330,"elapsed":3718,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"fdd6b0c6-ec79-4ec1-e2d6-d35aaef6388a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Fine-tuning loop with validation and model checkpointing\n","num_epochs = 3\n","best_loss = 9999\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    model.train()\n","\n","    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\"):\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    average_loss = total_loss / len(train_dataloader)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}: Training Loss - {average_loss}\")\n","\n","    if average_loss < best_loss:\n","        best_loss = average_loss\n","        model.save_pretrained(\"/content/drive/MyDrive/nlp_project/results/MT5_finetune/best_model_fine\")\n","        print(\"best model saved!\\n\\n\")\n","\n","print(\"Training completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tq9zNsEukImH","executionInfo":{"status":"ok","timestamp":1701890993430,"user_tz":-330,"elapsed":76592,"user":{"displayName":"Siddhant Shatapathy","userId":"00534836566549370750"}},"outputId":"9f697a3d-ac09-4c7d-d447-6d196942adc5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/3 (Training): 100%|██████████| 301/301 [00:24<00:00, 12.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3: Training Loss - 1.2617863386968442\n","best model saved!\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3 (Training): 100%|██████████| 301/301 [00:24<00:00, 12.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3: Training Loss - 1.1592591006890485\n","best model saved!\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3 (Training): 100%|██████████| 301/301 [00:24<00:00, 12.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3: Training Loss - 1.122371028626084\n","best model saved!\n","\n","\n","Training completed.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QDgN975rmNWH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JOIQvDu8mNSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tUN1KK6bmNQF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kFm4RV6jkIjE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QEjwuvhO0R2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HCWLVuR80Ry8"},"execution_count":null,"outputs":[]}]}