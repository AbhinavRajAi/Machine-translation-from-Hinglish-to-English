{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c7b28faff0fa479c9aa1fcbb90653cbc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df3d61a0bb984b25ac822aed07cd96d6","IPY_MODEL_a0fa5c41a16e4a50a5a123af3e39305c","IPY_MODEL_6a4f2cb4cc804d3fb341d2da4ebe18df"],"layout":"IPY_MODEL_c8ceaed62af34d7aa4af90cac9eb57f4"}},"df3d61a0bb984b25ac822aed07cd96d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae1506467c72455c99ac55cb73f4e7b7","placeholder":"​","style":"IPY_MODEL_c1cc2e80144d49caa1f7f6501a5074e9","value":"tokenizer_config.json: 100%"}},"a0fa5c41a16e4a50a5a123af3e39305c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_163be62a495247fa9ee3c855d91020e7","max":2324,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6addab2f0da64adcaef81ec1de78abe5","value":2324}},"6a4f2cb4cc804d3fb341d2da4ebe18df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4147381d84c40ae8c6e026dcac9319b","placeholder":"​","style":"IPY_MODEL_acd5478fb9044d4d84af6ecc0a81e543","value":" 2.32k/2.32k [00:00&lt;00:00, 86.0kB/s]"}},"c8ceaed62af34d7aa4af90cac9eb57f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae1506467c72455c99ac55cb73f4e7b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1cc2e80144d49caa1f7f6501a5074e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"163be62a495247fa9ee3c855d91020e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6addab2f0da64adcaef81ec1de78abe5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4147381d84c40ae8c6e026dcac9319b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acd5478fb9044d4d84af6ecc0a81e543":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea108e19f9094fcab90488fc7c8c322a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d63671300154272b342c423365388de","IPY_MODEL_82d6f2816a9d49f98321afccb7667a85","IPY_MODEL_40f25d660d32463db6779a1b19a23682"],"layout":"IPY_MODEL_c8a5c825f3b54d60aabfd6a346505e24"}},"4d63671300154272b342c423365388de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fa54198869e4b599aef65cd254cd642","placeholder":"​","style":"IPY_MODEL_cd08ed12f78440c78f3ae4b19a770a6f","value":"spiece.model: 100%"}},"82d6f2816a9d49f98321afccb7667a85":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ac7de33a4d24476877296973898f7ee","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2a1681601f949be936bb9aa15d81acc","value":791656}},"40f25d660d32463db6779a1b19a23682":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06e93e3f395545608e0d002571875145","placeholder":"​","style":"IPY_MODEL_6e65b9067a58473fb6770693e5135e3c","value":" 792k/792k [00:00&lt;00:00, 3.22MB/s]"}},"c8a5c825f3b54d60aabfd6a346505e24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fa54198869e4b599aef65cd254cd642":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd08ed12f78440c78f3ae4b19a770a6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ac7de33a4d24476877296973898f7ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2a1681601f949be936bb9aa15d81acc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06e93e3f395545608e0d002571875145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e65b9067a58473fb6770693e5135e3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1681310ca6b948ac94f2c7005a2a7a0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72a350921f954c6f9825f77e6ab60ef6","IPY_MODEL_1b6bf6005c284625870025ba56207bf2","IPY_MODEL_476ecff9fadc4bc79a90bffa4280e74a"],"layout":"IPY_MODEL_1ee7e5d52fc2430881bbfb94ae81cf10"}},"72a350921f954c6f9825f77e6ab60ef6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_950925b1176e45618f1d5013b2bb29d4","placeholder":"​","style":"IPY_MODEL_9be0255682c74caf8efd29e7587ac65e","value":"tokenizer.json: 100%"}},"1b6bf6005c284625870025ba56207bf2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e3481dedd944efcbcf55d9f669e1d09","max":1389353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7da71962a55c41faaa1a2196668a408a","value":1389353}},"476ecff9fadc4bc79a90bffa4280e74a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b165fffa370e41a682399be438451fcf","placeholder":"​","style":"IPY_MODEL_7548b96bf2124a97a5bd9038b38210b5","value":" 1.39M/1.39M [00:00&lt;00:00, 4.38MB/s]"}},"1ee7e5d52fc2430881bbfb94ae81cf10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"950925b1176e45618f1d5013b2bb29d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9be0255682c74caf8efd29e7587ac65e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e3481dedd944efcbcf55d9f669e1d09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7da71962a55c41faaa1a2196668a408a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b165fffa370e41a682399be438451fcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7548b96bf2124a97a5bd9038b38210b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece\n","!pip install sacremoses\n","!pip install git+https://github.com/nltk/nltk_contrib.git#egg=nltk_contrib\n","!pip install jiwer nltk sacrebleu rouge-score\n","!pip install --upgrade jiwer\n","!pip install torchmetrics\n","!pip install evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndFRkZSz-WbP","executionInfo":{"status":"ok","timestamp":1701880452806,"user_tz":-330,"elapsed":82964,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"12d0f829-e9a7-4f36-b2a2-3aa5fb295c20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Collecting sacremoses\n","  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.6.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.1)\n","Installing collected packages: sacremoses\n","Successfully installed sacremoses-0.1.1\n","Collecting nltk_contrib\n","  Cloning https://github.com/nltk/nltk_contrib.git to /tmp/pip-install-psm_1w3t/nltk-contrib_67205cc6ee7047729a6d3b6d64aa0ac6\n","  Running command git clone --filter=blob:none --quiet https://github.com/nltk/nltk_contrib.git /tmp/pip-install-psm_1w3t/nltk-contrib_67205cc6ee7047729a6d3b6d64aa0ac6\n","  Resolved https://github.com/nltk/nltk_contrib.git to commit 95d1806e2f4e89e960b76a685b1fba2eaa7d5142\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: nltk_contrib\n","  Building wheel for nltk_contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk_contrib: filename=nltk_contrib-3.8.1-py3-none-any.whl size=682136 sha256=cc9ab0a41f059396500a283d2879618825e1c3da1ef83a300221482273e84b9e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-wbfacxco/wheels/df/ab/e3/f99b22cdc83586c32ba851d962379a56a1e7f1bdb50aa41f7a\n","Successfully built nltk_contrib\n","Installing collected packages: nltk_contrib\n","Successfully installed nltk_contrib-3.8.1\n","Collecting jiwer\n","  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n","Collecting rapidfuzz<4,>=3 (from jiwer)\n","  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n","Collecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=0b2c37275db90bbb856b9369c290c3aaa120c8323e8f57856f71636461ee9b7a\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: rapidfuzz, portalocker, colorama, sacrebleu, rouge-score, jiwer\n","Successfully installed colorama-0.4.6 jiwer-3.0.3 portalocker-2.8.2 rapidfuzz-3.5.2 rouge-score-0.1.2 sacrebleu-2.3.3\n","Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n","Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.5.2)\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n","Collecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n","  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n","Collecting dill (from evaluate)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Collecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Installing collected packages: pyarrow-hotfix, dill, responses, multiprocess, datasets, evaluate\n","Successfully installed datasets-2.15.0 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0\n"]}]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import MarianMTModel, MarianTokenizer, AdamW,AutoTokenizer\n","from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n","import sacrebleu\n","from nltk.translate.meteor_score import meteor_score\n","import jiwer\n","from jiwer import wer\n","from rouge_score import rouge_scorer\n","from torchmetrics.text import TranslationEditRate\n","from tqdm import tqdm\n","import evaluate\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","from transformers import AutoModelForSeq2SeqLM\n"],"metadata":{"id":"27QkcJsp-Y2R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### MarianMT eval - synthetic data"],"metadata":{"id":"SL8Qv9h9ZxzM"}},{"cell_type":"code","source":["# Define the translation dataset with references\n","class TranslationDatasetWithRefs(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-cs\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(' '.join(input_text.split()[:100]), return_tensors='pt',truncation=True,padding='max_length', max_length=100)['input_ids'].squeeze()\n","        labels = self.tokenizer(' '.join(target_text.split()[:100]), return_tensors='pt',truncation=True,padding='max_length', max_length=100)['input_ids'].squeeze()\n","\n","        # Convert labels to text without special tokens\n","        references = [self.tokenizer.decode(labels, skip_special_tokens=True)]\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels, \"references\": references}"],"metadata":{"id":"RX_C2x9R-dGY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the test data\n","test_df = pd.read_csv(\"/content/drive/MyDrive/SEM 3/NLP/nlp_project/Dataset/test.tsv\", delimiter='\\t')"],"metadata":{"id":"ZN6l_lSO-2R0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a translation dataset and dataloader for testing\n","test_dataset = TranslationDatasetWithRefs(test_df)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"YwGy_TPK_J5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up the model and optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"2qfLb5ICAbW9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the best model\n","model = MarianMTModel.from_pretrained(\"/content/drive/MyDrive/SEM 3/NLP/nlp_project/results/MarianMT/best_model\").to(device)\n","\n","model.eval()\n","bleu_scores = []\n","wer_scores = []\n","ter_scores = []\n","meteor_scores = []\n","rouge1_scores = []\n","rouge2_scores = []\n","#ter = TranslationEditRate(normalize=True)\n","\n","\n","# Load the TER metric\n","ter = evaluate.load(\"ter\")\n","wer = evaluate.load(\"wer\")\n","rouge = evaluate.load('rouge')\n","bleu = evaluate.load(\"bleu\")\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Testing\"):\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","        references = batch['references']\n","\n","\n","        # Generate predictions\n","        generated_ids = model.generate(input_ids, max_length=100)  # Adjust max_length as needed\n","\n","        # Convert generated IDs to text\n","        predictions = [test_dataset.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)]\n","\n","\n","        # Convert generated IDs to text\n","        #predictions = [val_dataset.tokenizer.decode(generated_ids[0], skip_special_tokens=True)]\n","\n","        bleu_score = bleu.compute(predictions=predictions[0], references=references[0])\n","        bleu_scores.append(bleu_score['bleu'])\n","\n","\n","        # Calculate WER score\n","        wer_score = wer.compute(predictions=predictions[0],references=references[0])\n","        wer_scores.append(wer_score)\n","\n","        # Calculate TER score\n","        ter_score = ter.compute(predictions=predictions[0],references=references[0],\n","                       case_sensitive=False)\n","        #ter_score = TER(references[0][0], predictions[0])\n","        ter_scores.append(ter_score['score'])\n","\n","        # Calculate ROUGE score\n","        rouge_score = rouge.compute(predictions=predictions[0],references=references[0])\n","        rouge1_scores.append(rouge_score['rouge1'])\n","        rouge2_scores.append(rouge_score['rouge2'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BAo5ulsA_M0X","executionInfo":{"status":"ok","timestamp":1701886746005,"user_tz":-330,"elapsed":307318,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"6228b8b5-8bf0-4f3c-8259-67a4589eca93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 319/319 [04:57<00:00,  1.07it/s]\n"]}]},{"cell_type":"code","source":["# Calculate average scores\n","avg_bleu = sum(bleu_scores) / len(bleu_scores)\n","avg_wer = sum(wer_scores) / len(wer_scores)\n","avg_ter = sum(ter_scores) / len(ter_scores)\n","avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n","avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n","\n","# Print metric values\n","print(\"Testing Scores\")\n","print(\"Metric\\t\\t\\tWER\\t\\t\\tTER\\t\\t\\tBLEU\\t\\t\\tROUGE-1\\t\\t\\tROUGE-2\")\n","print(f\"Averages\\t\\t{avg_wer:.4f}\\t\\t\\t{avg_ter/100:.4f}\\t\\t\\t{avg_bleu:.4f}\\t\\t\\t{avg_rouge1:.4f}\\t\\t\\t{avg_rouge2:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BIAB8ecv_Oz2","executionInfo":{"status":"ok","timestamp":1701887529099,"user_tz":-330,"elapsed":686,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"b2119b67-1b4f-4371-cbd5-404f1ea5c8da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing Scores\n","Metric\t\t\tWER\t\t\tTER\t\t\tBLEU\t\t\tROUGE-1\t\t\tROUGE-2\n","Averages\t\t0.3072\t\t\t0.2392\t\t\t0.6082\t\t\t0.8761\t\t\t0.7171\n"]}]},{"cell_type":"markdown","source":["Testing Scores\n","Metric\t\t\tWER\t\t\tTER\t\t\tBLEU\t\t\tROUGE-1\t\t\tROUGE-2\n","Averages\t\t0.3072\t\t\t0.2392\t\t\t0.6082\t\t\t0.8761\t\t\t0.7171"],"metadata":{"id":"1Hng-6s5fxcJ"}},{"cell_type":"code","source":[],"metadata":{"id":"s1xZwZ1REUJh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### MBART eval - synthetic data"],"metadata":{"id":"-_O-jHjVZ5iw"}},{"cell_type":"code","source":["# Define the translation dataset with references\n","class TranslationDatasetWithRefs(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(' '.join(input_text.split()[:50]), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","        labels = self.tokenizer(' '.join(target_text.split()[:50]), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","\n","        # Convert labels to text without special tokens\n","        references = [self.tokenizer.decode(labels, skip_special_tokens=True)]\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels, \"references\": references}"],"metadata":{"id":"4sN6dlOoZ7G3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a translation dataset and dataloader for testing\n","test_dataset = TranslationDatasetWithRefs(test_df)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"GZFXWka5aR4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the best model\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/SEM 3/NLP/nlp_project/results/MBART_large/best_model\").to(device)\n","model.eval()\n","bleu_scores = []\n","wer_scores = []\n","ter_scores = []\n","meteor_scores = []\n","rouge1_scores = []\n","rouge2_scores = []\n","#ter = TranslationEditRate(normalize=True)\n","\n","\n","# Load the TER metric\n","ter = evaluate.load(\"ter\")\n","wer = evaluate.load(\"wer\")\n","rouge = evaluate.load('rouge')\n","bleu = evaluate.load(\"bleu\")\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Testing\"):\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","        references = batch['references']\n","\n","\n","        # Generate predictions\n","        generated_ids = model.generate(input_ids, max_length=100)  # Adjust max_length as needed\n","\n","        # Convert generated IDs to text\n","        predictions = [test_dataset.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)]\n","\n","\n","        # Convert generated IDs to text\n","        #predictions = [val_dataset.tokenizer.decode(generated_ids[0], skip_special_tokens=True)]\n","\n","        bleu_score = bleu.compute(predictions=predictions[0], references=references[0])\n","        bleu_scores.append(bleu_score['bleu'])\n","\n","\n","        # Calculate WER score\n","        wer_score = wer.compute(predictions=predictions[0],references=references[0])\n","        wer_scores.append(wer_score)\n","\n","        # Calculate TER score\n","        ter_score = ter.compute(predictions=predictions[0],references=references[0],\n","                       case_sensitive=False)\n","        #ter_score = TER(references[0][0], predictions[0])\n","        ter_scores.append(ter_score['score'])\n","\n","        # Calculate ROUGE score\n","        rouge_score = rouge.compute(predictions=predictions[0],references=references[0])\n","        rouge1_scores.append(rouge_score['rouge1'])\n","        rouge2_scores.append(rouge_score['rouge2'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"irj7Ge_Oaa85","executionInfo":{"status":"ok","timestamp":1701889015131,"user_tz":-330,"elapsed":826039,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"21035632-3ce3-4068-db15-e79110479bec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 319/319 [12:53<00:00,  2.43s/it]\n"]}]},{"cell_type":"code","source":["# Calculate average scores\n","avg_bleu = sum(bleu_scores) / len(bleu_scores)\n","avg_wer = sum(wer_scores) / len(wer_scores)\n","avg_ter = sum(ter_scores) / len(ter_scores)\n","avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n","avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n","\n","# Print metric values\n","print(\"Testing Scores\")\n","print(\"Metric\\t\\t\\tWER\\t\\t\\tTER\\t\\t\\tBLEU\\t\\t\\tROUGE-1\\t\\t\\tROUGE-2\")\n","print(f\"Averages\\t\\t{avg_wer:.4f}\\t\\t\\t{avg_ter/100:.4f}\\t\\t\\t{avg_bleu:.4f}\\t\\t\\t{avg_rouge1:.4f}\\t\\t\\t{avg_rouge2:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CifjrKN4axSe","executionInfo":{"status":"ok","timestamp":1701889070755,"user_tz":-330,"elapsed":389,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"150e4591-cc8d-48f1-f983-0827079ee184"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing Scores\n","Metric\t\t\tWER\t\t\tTER\t\t\tBLEU\t\t\tROUGE-1\t\t\tROUGE-2\n","Averages\t\t0.2647\t\t\t0.2014\t\t\t0.6562\t\t\t0.8990\t\t\t0.7573\n"]}]},{"cell_type":"markdown","source":["Testing Scores\n","Metric\t\t\tWER\t\t\tTER\t\t\tBLEU\t\t\tROUGE-1\t\t\tROUGE-2\n","Averages\t\t0.2647\t\t\t0.2014\t\t\t0.6562\t\t\t0.8990\t\t\t0.7573"],"metadata":{"id":"ddnkn4apfujK"}},{"cell_type":"code","source":[],"metadata":{"id":"JsUadZciflCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LCB8w8-tftSy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ag2iGCj8ftPz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### MT5 eval -synthetic data"],"metadata":{"id":"jCmeA2O9fqE7"}},{"cell_type":"code","source":["# Define the translation dataset with references\n","class TranslationDatasetWithRefs(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(' '.join(input_text.split()[:50]), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","        labels = self.tokenizer(' '.join(target_text.split()[:50]), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","\n","        # Convert labels to text without special tokens\n","        references = [self.tokenizer.decode(labels, skip_special_tokens=True)]\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels, \"references\": references}"],"metadata":{"id":"FsjO8GYxfsjn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a translation dataset and dataloader for testing\n","test_dataset = TranslationDatasetWithRefs(test_df)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["c7b28faff0fa479c9aa1fcbb90653cbc","df3d61a0bb984b25ac822aed07cd96d6","a0fa5c41a16e4a50a5a123af3e39305c","6a4f2cb4cc804d3fb341d2da4ebe18df","c8ceaed62af34d7aa4af90cac9eb57f4","ae1506467c72455c99ac55cb73f4e7b7","c1cc2e80144d49caa1f7f6501a5074e9","163be62a495247fa9ee3c855d91020e7","6addab2f0da64adcaef81ec1de78abe5","f4147381d84c40ae8c6e026dcac9319b","acd5478fb9044d4d84af6ecc0a81e543","ea108e19f9094fcab90488fc7c8c322a","4d63671300154272b342c423365388de","82d6f2816a9d49f98321afccb7667a85","40f25d660d32463db6779a1b19a23682","c8a5c825f3b54d60aabfd6a346505e24","6fa54198869e4b599aef65cd254cd642","cd08ed12f78440c78f3ae4b19a770a6f","1ac7de33a4d24476877296973898f7ee","d2a1681601f949be936bb9aa15d81acc","06e93e3f395545608e0d002571875145","6e65b9067a58473fb6770693e5135e3c","1681310ca6b948ac94f2c7005a2a7a0c","72a350921f954c6f9825f77e6ab60ef6","1b6bf6005c284625870025ba56207bf2","476ecff9fadc4bc79a90bffa4280e74a","1ee7e5d52fc2430881bbfb94ae81cf10","950925b1176e45618f1d5013b2bb29d4","9be0255682c74caf8efd29e7587ac65e","6e3481dedd944efcbcf55d9f669e1d09","7da71962a55c41faaa1a2196668a408a","b165fffa370e41a682399be438451fcf","7548b96bf2124a97a5bd9038b38210b5"]},"id":"rJzfkASEha4k","executionInfo":{"status":"ok","timestamp":1701889681542,"user_tz":-330,"elapsed":2912,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"4502c12b-fd01-440a-e590-b1528a14b1ec"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7b28faff0fa479c9aa1fcbb90653cbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea108e19f9094fcab90488fc7c8c322a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1681310ca6b948ac94f2c7005a2a7a0c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["# Load the best model\n","model = T5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/SEM 3/NLP/nlp_project/results/MT5_small/best_model\").to(device)\n","model.eval()\n","bleu_scores = []\n","wer_scores = []\n","ter_scores = []\n","meteor_scores = []\n","rouge1_scores = []\n","rouge2_scores = []\n","#ter = TranslationEditRate(normalize=True)\n","\n","\n","# Load the TER metric\n","ter = evaluate.load(\"ter\")\n","wer = evaluate.load(\"wer\")\n","rouge = evaluate.load('rouge')\n","bleu = evaluate.load(\"bleu\")\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Testing\"):\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","        references = batch['references']\n","\n","\n","        # Generate predictions\n","        generated_ids = model.generate(input_ids, max_length=50)  # Adjust max_length as needed\n","\n","        # Convert generated IDs to text\n","        predictions = [test_dataset.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)]\n","\n","\n","        # Convert generated IDs to text\n","        #predictions = [val_dataset.tokenizer.decode(generated_ids[0], skip_special_tokens=True)]\n","\n","        bleu_score = bleu.compute(predictions=predictions[0], references=references[0])\n","        bleu_scores.append(bleu_score['bleu'])\n","\n","\n","        # Calculate WER score\n","        wer_score = wer.compute(predictions=predictions[0],references=references[0])\n","        wer_scores.append(wer_score)\n","\n","        # Calculate TER score\n","        ter_score = ter.compute(predictions=predictions[0],references=references[0],\n","                       case_sensitive=False)\n","        #ter_score = TER(references[0][0], predictions[0])\n","        ter_scores.append(ter_score['score'])\n","\n","        # Calculate ROUGE score\n","        rouge_score = rouge.compute(predictions=predictions[0],references=references[0])\n","        rouge1_scores.append(rouge_score['rouge1'])\n","        rouge2_scores.append(rouge_score['rouge2'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_zlgSJzzhv3g","executionInfo":{"status":"ok","timestamp":1701890036054,"user_tz":-330,"elapsed":327697,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"07ff788a-5840-41ce-df58-72d6a9f8551e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 319/319 [05:16<00:00,  1.01it/s]\n"]}]},{"cell_type":"code","source":["# Calculate average scores\n","avg_bleu = sum(bleu_scores) / len(bleu_scores)\n","avg_wer = sum(wer_scores) / len(wer_scores)\n","avg_ter = sum(ter_scores) / len(ter_scores)\n","avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n","avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n","\n","# Print metric values\n","print(\"Testing Scores\")\n","print(\"Metric\\t\\t\\tWER\\t\\t\\tTER\\t\\t\\tBLEU\\t\\t\\tROUGE-1\\t\\t\\tROUGE-2\")\n","print(f\"Averages\\t\\t{avg_wer:.4f}\\t\\t\\t{avg_ter/100:.4f}\\t\\t\\t{avg_bleu:.4f}\\t\\t\\t{avg_rouge1:.4f}\\t\\t\\t{avg_rouge2:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4vSIyaFiA6E","executionInfo":{"status":"ok","timestamp":1701890194670,"user_tz":-330,"elapsed":6,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"ac5c62e8-03d4-4a56-8c7c-108ab6acb69d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing Scores\n","Metric\t\t\tWER\t\t\tTER\t\t\tBLEU\t\t\tROUGE-1\t\t\tROUGE-2\n","Averages\t\t0.9738\t\t\t0.9162\t\t\t0.2369\t\t\t0.5685\t\t\t0.3587\n"]}]},{"cell_type":"markdown","source":["Testing Scores\n","Metric\t\t\tWER\t\t\tTER\t\t\tBLEU\t\t\tROUGE-1\t\t\tROUGE-2\n","Averages\t\t0.9738\t\t\t0.9162\t\t\t0.2369\t\t\t0.5685\t\t\t0.3587"],"metadata":{"id":"AS7zJ_xYj76n"}},{"cell_type":"code","source":[],"metadata":{"id":"eC7L2-Jrj3dS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pK11xLLQkCLu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Fine tuned MBART evaluation on phinc"],"metadata":{"id":"RWUNWUAij_O6"}},{"cell_type":"code","source":["# Load the test data\n","test_df = pd.read_csv(\"/content/drive/MyDrive/SEM 3/NLP/nlp_project/Dataset/phinc/test.csv\")"],"metadata":{"id":"9BhCkhP3kBmf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the translation dataset with references\n","class TranslationDatasetWithRefs(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(' '.join(str(input_text).split()), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","        labels = self.tokenizer(' '.join(str(target_text).split()), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","\n","        # Convert labels to text without special tokens\n","        references = [self.tokenizer.decode(labels, skip_special_tokens=True)]\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels, \"references\": references}"],"metadata":{"id":"R-huTg6Nkqku"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a translation dataset and dataloader for testing\n","test_dataset = TranslationDatasetWithRefs(test_df)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"_OjKeXgfktuE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the best model\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/SEM 3/NLP/nlp_project/results/MBART_finetune/best_model_fine\").to(device)\n","model.eval()\n","bleu_scores = []\n","wer_scores = []\n","ter_scores = []\n","meteor_scores = []\n","rouge1_scores = []\n","rouge2_scores = []\n","#ter = TranslationEditRate(normalize=True)\n","\n","\n","# Load the TER metric\n","ter = evaluate.load(\"ter\")\n","wer = evaluate.load(\"wer\")\n","rouge = evaluate.load('rouge')\n","bleu = evaluate.load(\"bleu\")\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Testing\"):\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","        references = batch['references']\n","\n","\n","        # Generate predictions\n","        generated_ids = model.generate(input_ids, max_length=100)  # Adjust max_length as needed\n","\n","        # Convert generated IDs to text\n","        predictions = [test_dataset.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)]\n","\n","\n","        # Convert generated IDs to text\n","        #predictions = [val_dataset.tokenizer.decode(generated_ids[0], skip_special_tokens=True)]\n","\n","        bleu_score = bleu.compute(predictions=predictions[0], references=references[0])\n","        bleu_scores.append(bleu_score['bleu'])\n","\n","\n","        # Calculate WER score\n","        wer_score = wer.compute(predictions=predictions[0],references=references[0])\n","        wer_scores.append(wer_score)\n","\n","        # Calculate TER score\n","        ter_score = ter.compute(predictions=predictions[0],references=references[0],\n","                       case_sensitive=False)\n","        #ter_score = TER(references[0][0], predictions[0])\n","        ter_scores.append(ter_score['score'])\n","\n","        # Calculate ROUGE score\n","        rouge_score = rouge.compute(predictions=predictions[0],references=references[0])\n","        rouge1_scores.append(rouge_score['rouge1'])\n","        rouge2_scores.append(rouge_score['rouge2'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvYVemPkkzBp","executionInfo":{"status":"ok","timestamp":1701890926613,"user_tz":-330,"elapsed":233876,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"298ba86d-069a-40fb-9902-a11c18f8d145"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 39/39 [02:39<00:00,  4.10s/it]\n"]}]},{"cell_type":"code","source":["# Calculate average scores\n","avg_bleu = sum(bleu_scores) / len(bleu_scores)\n","avg_wer = sum(wer_scores) / len(wer_scores)\n","avg_ter = sum(ter_scores) / len(ter_scores)\n","avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n","avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n","\n","# Print metric values\n","print(\"Testing Scores\")\n","print(\"Metric\\t\\t\\tWER\\t\\t\\tTER\\t\\t\\tBLEU\\t\\t\\tROUGE-1\\t\\t\\tROUGE-2\")\n","print(f\"Averages\\t\\t{avg_wer:.4f}\\t\\t\\t{avg_ter/100:.4f}\\t\\t\\t{avg_bleu:.4f}\\t\\t\\t{avg_rouge1:.4f}\\t\\t\\t{avg_rouge2:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBk0oBDDlxKG","executionInfo":{"status":"ok","timestamp":1701890941905,"user_tz":-330,"elapsed":491,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"4f485e88-76fa-4f9b-fa0b-573418ed7901"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing Scores\n","Metric\t\t\tWER\t\t\tTER\t\t\tBLEU\t\t\tROUGE-1\t\t\tROUGE-2\n","Averages\t\t0.6925\t\t\t0.6304\t\t\t0.2194\t\t\t0.5351\t\t\t0.3012\n"]}]},{"cell_type":"markdown","source":["Testing Scores\n","Metric\t\t\tWER\t\t\tTER\t\t\tBLEU\t\t\tROUGE-1\t\t\tROUGE-2\n","Averages\t\t0.6925\t\t\t0.6304\t\t\t0.2194\t\t\t0.5351\t\t\t0.3012"],"metadata":{"id":"IWGE1DiEmwgO"}},{"cell_type":"code","source":[],"metadata":{"id":"i3zhIvqAmt22"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eV6NR8vtnAkT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### MT5 fine tuned evaluation on phinc data"],"metadata":{"id":"_AWwm9N-nA5H"}},{"cell_type":"code","source":["# Load the test data\n","test_df = pd.read_csv(\"/content/drive/MyDrive/SEM 3/NLP/nlp_project/Dataset/phinc/test.csv\")"],"metadata":{"id":"6rvirJmwnF6V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the translation dataset with references\n","class TranslationDatasetWithRefs(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_text = self.data['cs_query'][idx]\n","        target_text = self.data['en_query'][idx]\n","\n","        input_ids = self.tokenizer(' '.join(str(input_text).split()), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","        labels = self.tokenizer(' '.join(str(target_text).split()), return_tensors='pt',truncation=True,padding='max_length', max_length=50)['input_ids'].squeeze()\n","\n","        # Convert labels to text without special tokens\n","        references = [self.tokenizer.decode(labels, skip_special_tokens=True)]\n","\n","        return {\"input_ids\": input_ids, \"labels\": labels, \"references\": references}"],"metadata":{"id":"NuIMB3xbnOkh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a translation dataset and dataloader for testing\n","test_dataset = TranslationDatasetWithRefs(test_df)\n","test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NUTVMFBKnOhL","executionInfo":{"status":"ok","timestamp":1701891370603,"user_tz":-330,"elapsed":1194,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"c1a6d8bf-d388-424f-fe10-18e0f4dbba2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["# Load the best model\n","model = T5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/SEM 3/NLP/nlp_project/results/MT5_finetune/best_model_fine\").to(device)\n","model.eval()\n","bleu_scores = []\n","wer_scores = []\n","ter_scores = []\n","meteor_scores = []\n","rouge1_scores = []\n","rouge2_scores = []\n","#ter = TranslationEditRate(normalize=True)\n","\n","\n","# Load the TER metric\n","ter = evaluate.load(\"ter\")\n","wer = evaluate.load(\"wer\")\n","rouge = evaluate.load('rouge')\n","bleu = evaluate.load(\"bleu\")\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Testing\"):\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","        references = batch['references']\n","\n","\n","        # Generate predictions\n","        generated_ids = model.generate(input_ids, max_length=100)  # Adjust max_length as needed\n","\n","        # Convert generated IDs to text\n","        predictions = [test_dataset.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)]\n","\n","\n","        # Convert generated IDs to text\n","        #predictions = [val_dataset.tokenizer.decode(generated_ids[0], skip_special_tokens=True)]\n","\n","        bleu_score = bleu.compute(predictions=predictions[0], references=references[0])\n","        bleu_scores.append(bleu_score['bleu'])\n","\n","\n","        # Calculate WER score\n","        wer_score = wer.compute(predictions=predictions[0],references=references[0])\n","        wer_scores.append(wer_score)\n","\n","        # Calculate TER score\n","        ter_score = ter.compute(predictions=predictions[0],references=references[0],\n","                       case_sensitive=False)\n","        #ter_score = TER(references[0][0], predictions[0])\n","        ter_scores.append(ter_score['score'])\n","\n","        # Calculate ROUGE score\n","        rouge_score = rouge.compute(predictions=predictions[0],references=references[0])\n","        rouge1_scores.append(rouge_score['rouge1'])\n","        rouge2_scores.append(rouge_score['rouge2'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0ETkdnrnIDD","executionInfo":{"status":"ok","timestamp":1701891555992,"user_tz":-330,"elapsed":183903,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"df301e34-53c1-47bd-a51e-ff92b3252cbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 155/155 [02:54<00:00,  1.12s/it]\n"]}]},{"cell_type":"code","source":["# Calculate average scores\n","avg_bleu = sum(bleu_scores) / len(bleu_scores)\n","avg_wer = sum(wer_scores) / len(wer_scores)\n","avg_ter = sum(ter_scores) / len(ter_scores)\n","avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n","avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n","\n","# Print metric values\n","print(\"Testing Scores\")\n","print(\"Metric\\t\\t\\tWER\\t\\t\\tTER\\t\\t\\tBLEU\\t\\t\\tROUGE-1\\t\\t\\tROUGE-2\")\n","print(f\"Averages\\t\\t{avg_wer:.4f}\\t\\t\\t{avg_ter/100:.4f}\\t\\t\\t{avg_bleu:.4f}\\t\\t\\t{avg_rouge1:.4f}\\t\\t\\t{avg_rouge2:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9BAzee4nH_k","executionInfo":{"status":"ok","timestamp":1701891559221,"user_tz":-330,"elapsed":521,"user":{"displayName":"Siddhant Shatapathy","userId":"12135462636345410446"}},"outputId":"02e05a68-f474-4425-b695-8139993f0204"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing Scores\n","Metric\t\t\tWER\t\t\tTER\t\t\tBLEU\t\t\tROUGE-1\t\t\tROUGE-2\n","Averages\t\t1.1808\t\t\t1.1411\t\t\t0.1011\t\t\t0.2897\t\t\t0.1488\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pdBokYmOoOaL"},"execution_count":null,"outputs":[]}]}